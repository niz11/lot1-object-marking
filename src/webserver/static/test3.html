<!DOCTYPE html>
<meta name="viewport"
      content="width=device-width, user-scalable=no, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0">
<title>Hello, AR Cubes!</title>
<!-- include three.js library -->
<script src='new/three.js'></script>
<script src='new/GLTFLoader.js'></script>
<script src='new/EventDispatcher.js'></script>
<!-- include jsartookit -->
<script src="jsartoolkit5/artoolkit.min.js"></script>
<script src="jsartoolkit5/artoolkit.api.js"></script>
<!-- include threex.artoolkit -->

<!--<script src="js/ar.js"></script>-->
<script src="threex/threex-artoolkitsource.js"></script>
<script src="threex/threex-artoolkitcontext.js"></script>
<script src="threex/threex-arbasecontrols.js"></script>
<script src="threex/threex-armarkercontrols.js"></script>

<body style='margin : 0px; overflow: hidden; font-family: Monospace;'>
<button onclick="activateXR()" style="z-index: 5;">Start Hello WebXR</button>
<div style='position: absolute; top: 10px; width:100%; text-align: center;z-index:1;'>
    <p id = 'mct'>Marker Control:</p> <br>
    <p id = 'mcx'></p> <br>
    <p id = 'mcy'></p> <br>
    <p id = 'mcz'></p> <br>
    <p id = 'mcw'></p> <br>
</div>


<script>
    var sceneARJS, cameraARJS, camera2ARJS, renderer, clock, deltaTime, totalTime, mesh, markerControls;
    var arToolkitSource, arToolkitContext;

    var firstUpdate = false;

    var canvas, gl;

    // initialize();
    // animate();
    // Add a canvas element and initialize a WebGL context that is compatible with WebXR.
    canvas = document.createElement("canvas");
    document.body.appendChild(canvas);
    gl = canvas.getContext("webgl", { xrCompatible: true });



    // Set up the WebGLRenderer, which handles rendering to the session's base layer.
    renderer = new THREE.WebGLRenderer({
        alpha: true,
        preserveDrawingBuffer: true,
        canvas: canvas,
        context: gl
    });
    renderer.autoClear = false;
    function initialize() {
        sceneARJS = new THREE.Scene();

        let ambientLight = new THREE.AmbientLight(0xcccccc, 0.5);
        sceneARJS.add(ambientLight);

        cameraARJS = new THREE.OrthographicCamera(window.innerWidth / -2, window.innerWidth / 2, window.innerHeight / -2, window.innerHeight / 2, -100, 100);
        sceneARJS.add(cameraARJS);





        mesh = new THREE.Mesh(
            new THREE.BoxGeometry(5, 10, 10),
            new THREE.MeshBasicMaterial({color: 0xff0000})
        );
        sceneARJS.add(mesh);
        cameraARJS.position.z = 5;

        arToolkitSource = new THREEx.ArToolkitSource({
            sourceType: 'webcam',
            showVideo: false
        });

        arToolkitSource.init(function onReady() {
            onResize()
        });

        // handle resize
        window.addEventListener('resize', function () {
            onResize()
        });

        window.addEventListener('arjs-video-loaded', function () {
            onResize()
        });

        window.addEventListener("markerFound", function (e) {
            console.log("Found")
        });
        window.addEventListener("markerLost", function (e) {
            console.log("Lost")
        });

        function onResize() {
            arToolkitSource.onResizeElement();
            arToolkitSource.copyElementSizeTo(renderer.domElement)
            if (arToolkitContext.arController !== null) {
                arToolkitSource.copyElementSizeTo(arToolkitContext.arController.canvas)
            }
        }


        arToolkitContext = new THREEx.ArToolkitContext({
            cameraParametersUrl: 'data/camera_para.dat',
            detectionMode: 'mono',
            canvasWidth: 80 * 3,
            canvasHeight: 60 * 3,
            maxDetectionRate: 30
        });

        camera2ARJS = new THREE.Camera();
        arToolkitContext.init(function onCompleted() {
            camera2ARJS.projectionMatrix.copy(arToolkitContext.getProjectionMatrix());
        });

        let patternArray = ["letterA", "letterB", "letterC", "letterD", "letterF", "kanji", "hiro"];
        for (let i = 6; i < 7; i++) {
            let markerRoot = new THREE.Group();
            markerControls = new THREEx.ArMarkerControls(arToolkitContext, markerRoot, {
                type: 'pattern', patternUrl: "data/" + patternArray[i] + ".patt",
            });
        }
    }


    function update() {
        if (arToolkitSource.ready !== false) {
            arToolkitContext.update(arToolkitSource.domElement);
            if (!firstUpdate) {
                window.dispatchEvent(new CustomEvent('resize'));
                firstUpdate = true;
            }
        }


        if (markerControls.object3d.visible) {
            let pos = markerControls.object3d.position;
            let cpos = new THREE.Vector3(pos.x, pos.y, pos.z).project(camera2ARJS);
            document.getElementById('mcx').innerText = 'x: ' + cpos.x;
            document.getElementById('mcy').innerText = 'y: ' + cpos.y;
            document.getElementById('mcz').innerText = 'z: ' + cpos.z;

            mesh.position.x = cpos.x * window.innerWidth / 2;
            mesh.position.y = cpos.y * window.innerHeight / -2;
        }

        document.getElementById('mcw').innerText = 'visible: ' + markerControls.object3d.visible;
    }

    function animate() {
        // requestAnimationFrame(animate);
        return;
        update();
        renderer.render(sceneARJS, cameraARJS);
    }

    async function activateXR() {
        console.log("Hi there");


        const scene = new THREE.Scene();

        const directionalLight = new THREE.DirectionalLight(0xffffff, 0.3);
        directionalLight.position.set(10, 15, 10);
        scene.add(directionalLight);


        // The API directly updates the camera matrices.
        // Disable matrix auto updates so three.js doesn't attempt
        // to handle the matrices independently.
        const camera = new THREE.PerspectiveCamera();
        camera.matrixAutoUpdate = false;

        // Initialize a WebXR session using "immersive-ar".
        const session = await navigator.xr.requestSession("immersive-ar", { requiredFeatures: ['hit-test'] });
        session.updateRenderState({
            baseLayer: new XRWebGLLayer(session, gl)
        });

        // A 'local' reference space has a native origin that is located
        // near the viewer's position at the time the session was created.
        const referenceSpace = await session.requestReferenceSpace('local');
        // Create another XRReferenceSpace that has the viewer as the origin.
        const viewerSpace = await session.requestReferenceSpace('viewer');
        // Perform hit testing using the viewer as origin.
        const hitTestSource = await session.requestHitTestSource({ space: viewerSpace });
        const loader = new THREE.GLTFLoader();
        let reticle;
        loader.load("https://immersive-web.github.io/webxr-samples/media/gltf/reticle/reticle.gltf", function (gltf) {
            reticle = gltf.scene;
            reticle.visible = false;
            scene.add(reticle);
        })

        let flower;
        loader.load("https://immersive-web.github.io/webxr-samples/media/gltf/sunflower/sunflower.gltf", function (gltf) {
            flower = gltf.scene;
        });

        session.addEventListener("select", (event) => {
            if (flower) {
                flower.position.copy(reticle.position);
                scene.add(flower);
            }
        });

        // Here it's just an example of the marker value being switch after 10 seconds
        let marker = false;
        setTimeout(function () { marker = true }, 10000);
        // Create a render loop that allows us to draw on the AR view.
        const onXRFrame = (time, frame) => {
            // Queue up the next draw request.
            session.requestAnimationFrame(onXRFrame);

            // Bind the graphics framebuffer to the baseLayer's framebuffer
            gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer)

            // Retrieve the pose of the device.
            // XRFrame.getViewerPose can return null while the session attempts to establish tracking.
            const pose = frame.getViewerPose(referenceSpace);
            if (pose) {
                // In mobile AR, we only have one view.
                const view = pose.views[0];

                const viewport = session.renderState.baseLayer.getViewport(view);
                renderer.setSize(viewport.width, viewport.height)

                // Use the view's transform matrix and projection matrix to configure the THREE.camera.
                camera.matrix.fromArray(view.transform.matrix)
                camera.projectionMatrix.fromArray(view.projectionMatrix);
                camera.updateMatrixWorld(true);
                animate();
                //If marker was deected do hit test here
                if (marker) {
                    // console.log("marker detected");
                    const hitTestResults = frame.getHitTestResults(hitTestSource);
                    if (hitTestResults.length > 0 && reticle) {
                        const hitPose = hitTestResults[0].getPose(referenceSpace);
                        reticle.visible = true;
                        reticle.position.set(hitPose.transform.position.x, hitPose.transform.position.y, hitPose.transform.position.z)
                        reticle.updateMatrixWorld(true);
                    }
                }

                // Render the scene with THREE.WebGLRenderer.
                renderer.render(scene, camera)
            }
        }
        session.requestAnimationFrame(onXRFrame);
    }
</script>

</body>
</html>